{"posts":[{"title":"Biography","text":"Currently a third-year PhD student at The Hong Kong Polytechnic University under the supervision of Prof. Xiao-Ming Wu, and a visiting scholar at National University of Singapore under the supervision of Prof. Min-Yen Kan, Qijiong Liu (刘奇煚, Jyonn) obtained his B.Eng. and M.Eng. degrees from the School of Computer Science and Technology at Zhejiang University in 2018 and 2021, respectively. During his internships at Huawei, he worked on research projects related to recommender system and information retrieval. In 2020 and 2022, he worked as a research intern at Huawei Noah’s Ark Lab (Shenzhen) and Huawei Terminal Business Group (Nanjing), mentored by Jieming Zhu and Li Jiang, respectively. Moreover, he completed a one-year internship in San Jose during his senior year as part of the Cisco International Internship Program (CIIP), directed by Debo Dutta. To learn more about Qijiong Liu and access his resume, you can click on this link. *Thanks to Xingtong Yu for taking a nice photo of me when we were in Austin for TheWebConf 2023. It is used as the new favicon of this website and the profile picture on the homepage from Aug. 2023.","link":"/2020/10/01/Biography/"},{"title":"Semantic Tokenization for Deep CTR Prediction","text":"Our first exploration on semantic tokenization got published to TheWebConf 2024. Qijiong LIU, Hengchang HU, Jiahao WU, Jieming ZHU, Min-Yen KAN#, Xiao-Ming WU#[Code] [Paper] AbstractIncorporating item content knowledge into deep click-through rate (CTR) models remains challenging, particularly given the constraints of time and space efficiency in industrial scenarios. The content-based paradigm sacrifices time for space, while the embedding-based paradigm trades space for time. We introduce UIST, a user–item semantic tokenization approach guided by the semantic-based paradigm. UIST offers swift training and inference, maintaining limited memory usage. Unlike the embedding-based paradigm, which directly converts item and user semantics into a unified high-dimensional representation, UIST discretizes dense vectors into tokens with shorter lengths. Additionally, we design a hierarchical mixture inference module to analyze the contributions of each user-item token pair. Citation12345678@misc{liu2024semantic, title={Semantic Tokenization for Deep CTR Prediction}, author={Qijiong Liu and Hengchang Hu and Jiahao Wu and Jieming Zhu and Min-Yen Kan and Xiao-Ming Wu}, booktitle = {Proceedings of the ACM Web Conference 2024}, month = {may}, year = {2024}, address = {Singapore}}","link":"/2024/03/06/Research-UIST/"},{"title":"Lightweight Modality Adaptation to Sequential Recommendation via Correlation Supervision","text":"The second attempt to combine recommender systems with vector quantization technique, which is accepted by ECIR 2024.Congrats to Hengchang! Hengchang HU, Qijiong LIU, Chuang LI, Min-Yen KAN#[Code] [Paper] AbstractIn Sequential Recommenders (SR), encoding and utilizing modalities in an end-to-end manner is costly in terms of modality encoder sizes.Two-stage approaches can mitigate such concerns, but they suffer from poor performance due to modality forgetting, where the sequential objective overshadows modality representation.We propose a lightweight knowledge distillation solution that preserves both merits: retaining modality information and maintaining high efficiency.Specifically, we introduce a novel method that enhances the learning of embeddings in SR through the supervision of modality correlations.The supervision signals are distilled from the original modality representations, including both (1) holistic correlations, which quantify their overall associations, and (2) dissected correlation types, which refine their relationship facets (honing in on specific aspects like color or shape consistency).For the issue of rapidly overshadowed modal information, we propose an asynchronous learning step, allowing the original information to be preserved longer for training the representation learning module.Our approach is compatible with various backbone architectures, and it outperforms the top baselines by 6.8% on average.We empirically demonstrate that preserving original feature associations from modality encoders significantly aids in the recommendation task-specific adaptation.Additionally, we find that larger modality encoders (e.g., Large Language Models) contain richer feature sets and also necessitate more fine-grained modeling to reach their full performance potential. Citation123456789101112@inproceedings{hu2024lightweight, title = &quot;Lightweight Modality Adaptation to Sequential Recommendation via Correlation Supervision&quot;, author = &quot;Hu, Hengchang and Liu, Qijiong and Li, Chuang and Kan, Min-Yen&quot;, booktitle = &quot;European Conference on Information Retrieval&quot;, month = mar, year = &quot;2024&quot;, address = &quot;Glasgow, Scotland, UK&quot;, publisher = &quot;Springer International Publishing&quot;,}","link":"/2023/12/15/Research-KDSR/"},{"title":"Adaptive Image Grid Layout Tool","text":"IntroductionWe introduce a new image layout tool, which can automatically generate fancy image layouts for different image sizes and numbers. Fancy image layout is a common requirement in web design and event posters. However, it is difficult to achieve a satisfactory layout effect with traditional image layout tools. Those tools, usually have a fixed layout pattern, which may not be suitable for different image sizes and numbers. For example, some vertical images may be cropped, and some horizontal images may be too small to fill the entire layout. Web Demo Click anywhere on the layout to regenerate. Normal Style (Padding Ratio=0.05, Radius Ratio=0.05) Compact Style (Padding Ratio=0, Radius Ratio=0) Rounded Style (Padding Ratio=0.1, Radius Ratio=0.5) Web Linkhttps://grid.6-79.cn LicenseMIT Links GitHub Documentation","link":"/2023/11/30/Develop-ImageGrid/"},{"title":"Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation","text":"Our first exploration of dataset distillation work has been published on arXiv! Jiahao WU*, Qijiong LIU*, Hengchang HU, Wenqi FAN, Shengcai LIU, Qing LI#, Xiao-Ming WU#, and Ke TANG#*Equal contribution (co-first authors)[Code] [Paper] AbstractModern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dual-level condensation method: content-level and user-level. At content-level, we utilize LLMs to condense all contents of an item into a new informative title. At user-level, we design a clustering-based synthesis module, where we first utilize LLMs to extract user interests. Then, the user interests and user embeddings are incorporated to condense users and generate interactions for condensed users. Notably, the condensation paradigm of this method is forward and free from iterative optimization on the synthesized dataset. Extensive empirical findings from our study, conducted on three authentic datasets, substantiate the efficacy of the proposed method. Particularly, we are able to approximate up to 97% of the original performance while reducing the dataset size by 95% (i.e., on dataset MIND). Citation123456@article{wu2023leveraging, title={Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation}, author={Wu, Jiahao and Liu, Qijiong and Hu, Hengchang and Fan, Wenqi and Liu, Shengcai and Li, Qing and Wu, Xiao-Ming and Tang, Ke}, journal={arXiv preprint arXiv:2310.09874}, year={2023}}","link":"/2023/10/19/Research-DCon/"},{"title":"Pigmento: Colorize and Trace Printing","text":"IntroductionPigmento is a Python package that can colorize and trace printing. It can be used to quickly locate the source of the print statement.Moreover, it supports customizing the style of printing, prefixes, and powerful plugins. Installation1pip install pigmento Quick Start12345678910111213141516171819202122from pigmento import pntclass Test: @classmethod def class_method(cls): pnt('Hello World') def instance_method(self): pnt('Hello World') @staticmethod def static_method(): pnt('Hello World') def global_function(): pnt('Hello World')Test.class_method()Test().instance_method()Test.static_method()global_function() |Test| (class_method) Hello World |Test| (instance_method) Hello World |Test| (static_method) Hello World (global_function) Hello World Style Customization123456789101112from pigmento import pnt, Colorpnt.set_display_style( method_color=Color.RED, method_bracket=('&lt;', '&gt;'), class_color=Color.BLUE, class_bracket=('[', ']'),)Test.class_method()Test().instance_method()Test.static_method() [Test] &lt;class_method&gt; Hello World [Test] &lt;instance_method&gt; Hello World [Test] &lt;static_method&gt; Hello World Display Mode Customization1234567from pigmento import pntpnt.set_display_mode( display_method_name=False,)Test.class_method() |Test| Hello World PrefixesPigmento supports customized prefixes for each print.It is important to note that all prefixes are in first-in-first-print order. 12345from pigmento import pnt, Prefix, Color, Bracketpnt.add_prefix(Prefix('DEBUG', bracket=Bracket.DEFAULT, color=Color.GREEN))global_function() [DEBUG] (global_function) Hello World Dynamic PrefixTexts inside prefix can be dynamically generated. 123456789101112131415from pigmento import pnt, Prefix, Color, Bracketclass System: STATUS = 'TRAINING' @classmethod def get_status(cls): return cls.STATUS pnt.add_prefix(Prefix(System.get_status, bracket=Bracket.DEFAULT, color=Color.GREEN))global_function()System.STATUS = 'TESTING'global_function() [TRAINING] (global_function) Hello World [TESTING] (global_function) Hello World Build-in Time PrefixTimePrefix is a build-in prefix that can be used to display time. 123456789import timeimport pigmentofrom pigmento import pntpigmento.add_time_prefix()Test.class_method()time.sleep(1)Test.class_method() [00:00:00] |Test| (class_method) Hello World [00:00:01] |Test| (class_method) Hello World PluginsPigmento supports plugins to extend its functionalities. Build-in LoggerEverytime you print something, it will be logged to a file. 123456import pigmentofrom pigmento import pntpigmento.add_log_plugin('log.txt')global_function() (global_function) Hello World The log file will be created in the current working directory and the content will be removed the color codes. 1cat log.txt [00:00:00] (global_function) Hello World Build-in Dynamic ColorDynamicColor will map caller class names to colors. 12345678910111213141516171819202122232425262728293031import pigmentofrom pigmento import pntclass A: @staticmethod def print(): pnt(f'Hello from A')class B: @staticmethod def print(): pnt(f'Hello from B')class D: @staticmethod def print(): pnt(f'Hello from C')A().print()B().print()D().print()pigmento.add_dynamic_color_plugin()A().print()B().print()D().print() |A| (print) Hello from A |B| (print) Hello from B |D| (print) Hello from C |A| (print) Hello from A |B| (print) Hello from B |D| (print) Hello from C Plugin Customization12345678910111213141516from pigmento import pnt, BasePluginclass RenamePlugin(BasePlugin): def middleware_before_class_prefix(self, name, bracket, color): return name.lower(), bracket, color def middleware_before_method_prefix(self, name, bracket, color): return name.replace('_', '-'), bracket, colorpnt.add_plugin(RenamePlugin())Test.class_method()Test().instance_method()Test.static_method() |test| (class-method) Hello World |test| (instance-method) Hello World |test| (static-method) Hello World Multiple PrintersPigmento supports multiple printers. 123456789101112131415161718192021222324252627from pigmento import Pigmento, Bracket, Color, Prefixdebug = Pigmento()debug.add_prefix(Prefix('DEBUG', bracket=Bracket.DEFAULT, color=Color.GREEN))info = Pigmento()info.add_prefix(Prefix('INFO', bracket=Bracket.DEFAULT, color=Color.BLUE))error = Pigmento()error.add_prefix(Prefix('ERROR', bracket=Bracket.DEFAULT, color=Color.RED))def divide(a, b): if not isinstance(a, int) or not isinstance(b, int): error('Inputs must be integers') return if b == 0: debug('Cannot divide by zero') return info(f'{a} / {b} = {a / b}')divide(1, 2)divide(1, 0)divide('x', 'y') [INFO] (divide) 1 / 2 = 0.5 [DEBUG] (divide) Cannot divide by zero [ERROR] (divide) Inputs must be integers LicenseMIT License Links GitHub PyPI Documentation","link":"/2023/10/18/Develop-Pigmento/"},{"title":"Learning Category Trees for ID-Based Recommendation: Exploring the Power of Differentiable Vector Quantization","text":"Updated on Jan. 24, 2024: Our paper got published to TheWebConf 2024.Our first exploration work in the field of vector quantization has been published on arXiv! Qijiong LIU, Lu FAN*, Jiaren XIAO*, Jieming ZHU, and Xiao-Ming WU#*Equal contribution (co-second authors).[Code] [Paper] AbstractCategory information plays a crucial role in enhancing the quality and personalization of recommender systems. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose a novel approach to automatically learn and generate entity (i.e., user or item) category trees for ID-based recommendation. Specifically, we devise a differentiable vector quantization framework for automatic category tree generation, namely CAGE, which enables the simultaneous learning and refinement of categorical code representations and entity embeddings in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, CAGE can be easily integrated into both sequential and non-sequential recommender systems. We validate the effectiveness of CAGE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommendation models. We release the code and data for others to reproduce the reported results. Citation12345678@inproceedings{liu2024cage, title = {Learning Category Trees for ID-Based Recommendation: Exploring the Power of Differentiable Vector Quantization}, author = {Liu, Qijiong and Fan, Lu and Xiao, Jiaren and Zhu, Jieming and Wu, Xiao-Ming}, booktitle = {Proceedings of the ACM Web Conference 2024}, month = {may}, year = {2024}, address = {Singapore}}","link":"/2023/09/01/Research-CAGE/"},{"title":"ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models","text":"Updated on Oct. 20, 2023: Our paper combining large language models and recommender systems got published to WSDM 2024.Our paper combining large language models and recommender systems got updated in arXiv!First version (i.e., GENRE) discussed the use of closed-source LLMs (e.g., GPT-3.5) in recommender systems, while this version (i.e., ONCE) further combines open-source LLMs (e.g., LLaMA) and closed-source LLMs in recommender systems. Qijiong LIU, Nuo CHEN, Tetsuya SAKAI, and Xiao-Ming WU#[Code] [Paper] AbstractPersonalized content-based recommender systems have become indispensable tools for users to navigate through the vast amount of content available on platforms like daily news websites and book recommendation services. However, existing recommenders face significant challenges in understanding the content of items. Large language models (LLMs), which possess deep semantic comprehension and extensive knowledge from pretraining, have proven to be effective in various natural language processing tasks. In this study, we explore the potential of leveraging both open- and closed-source LLMs to enhance content-based recommendation. With open-source LLMs, we utilize their deep layers as content encoders, enriching the representation of content at the embedding level. For closed-source LLMs, we employ prompting techniques to enrich the training data at the token level. Through comprehensive experiments, we demonstrate the high effectiveness of both types of LLMs and show the synergistic relationship between them. Notably, we observed a significant relative improvement of up to 19.32% compared to existing state-of-the-art recommendation models. These findings highlight the immense potential of both open- and closed-source of LLMs in enhancing content-based recommendation systems. We will make our code and LLM-generated data available for other researchers to reproduce our results. Citation123456@inproceedings{liu2023once, title={ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models}, author={Qijiong Liu and Nuo Chen and Tetsuya Sakai and Xiao-Ming Wu}, booktitle={Proceedings of the Seventeen ACM International Conference on Web Search and Data Mining}, year={2024}}","link":"/2023/08/31/Research-ONCE/"},{"title":"Benchmarking News Recommendation in the Era of Green AI","text":"Updated on Mar. 6, 2024: Our paper got published to TheWebConf 2024. It is a revised and condensed version of the previous work titled Only Encode Once: Making Content-based News Recommender Greener. While the core ideas and results remain consistent, the presentation scope have been modified for brevity and clarity. For the full details and extended discussions, please refer to the original long paper at here.Our first piece of sustainable and green AI work has been published on arXiv! Qijiong LIU*, Jieming ZHU*, Quanyu DAI, Xiao-Ming WU#*Equal contribution (co-first authors).[Code] [Paper] AbstractOver recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992% improvement in sustainability metrics. We have released the source code and data for reproducibility. Citation12345678@misc{liu2024benchmarking, title={Benchmarking News Recommendation in the Era of Green AI}, author={Qijiong Liu and Jieming Zhu and Quanyu Dai and Xiao-Ming Wu}, booktitle = {Proceedings of the ACM Web Conference 2024}, month = {may}, year = {2024}, address = {Singapore}}","link":"/2023/08/29/Research-GreenRec/"},{"title":"Brand New Start at NUS","text":"I am very excited to announce that I will be joining the National University of Singapore as a visiting scholar in July 2023, working with Prof. Min-Yen Kan. The research topic will be related to information retrieval and multimodal learning. I am looking forward to this new journey!","link":"/2023/07/18/Brand-New-Start-at-NUS/"},{"title":"A First Look at LLM-powered Generative News Recommendation","text":"Our first exploration of large language model work has been published on arXiv!Updated on Oct. 10, 2023: Our work was introduced on DataFunTalk! Qijiong LIU, Nuo CHEN, Tetsuya SAKAI, and Xiao-Ming WU#[Code] [Paper] AbstractPersonalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. We will publish our code and data for other researchers to reproduce our work. Citation12345678@misc{liu2023look, title={A First Look at LLM-Powered Generative News Recommendation}, author={Qijiong Liu and Nuo Chen and Tetsuya Sakai and Xiao-Ming Wu}, year={2023}, eprint={2305.06566}, archivePrefix={arXiv}, primaryClass={cs.IR}}","link":"/2023/05/12/Research-GENRE/"},{"title":"FANS: Fast Non-autoregressive Sequential Generation for Item List Continuation","text":"Our exploration in the field of list completion has been accepted by TheWebConf 2023! Qijiong LIU, Jieming ZHU, Jiahao WU, Tiandeng WU, Zhenhua DONG, and Xiao-Ming WU#[Code] [Paper] AbstractUser-curated item lists, such as video-based playlists on Youtube and book-based lists on Goodreads, have become prevalent for sharing content on online platforms. Item list continuation is proposed to model the overall trend of lists and predict subsequent lists. Recently, Transformer-based models have shown promise in comprehending contextual information and capturing item relationships in a list. However, it is difficult to deploy them in real-time industrial scenarios, mainly due to the time-consuming nature of the autoregressive generation mechanism used in them. In this paper, we propose a novel fast non-autoregressive sequence generation model, namely FANS, to accelerate inference efficiency and improve inference quality for item list continuation. First, we use a non-autoregressive generation mechanism to decode next $K$ items simultaneously instead of one-by-one as in existing models. Then, we design a two-stage classifier to replace the vanilla classifier used in current Transformer-based models to further reduce the decoding time. Moreover, to improve inference quality of non-autoregressive generation, we employ a curriculum learning strategy to optimize training. Extensive experiments on four real-world item list continuation datasets including Zhihu, Spotify, AotM, and Goodreads demonstrate that our FANS model can significantly improve inference efficiency (up to 8.7x) while achieving competitive or better inference quality compared with state-of-the-art autoregressive models. We also validate the efficiency of FANS in an industrial system. The source code and data are provided for reproducing the reported results. Citation12345678@inproceedings{liu2023fans, title = {FANS: Fast Non-Autoregressive Sequence Generation for Item List Continuation}, author = {Liu, Qijiong and Zhu, Jieming and Wu, Jiahao and Wu, Tiandeng and Dong, Zhenhua and Wu, Xiao-Ming}, booktitle = {Proceedings of the ACM Web Conference 2023}, month = {may}, year = {2023}, address = {Austin, Texas, USA}}","link":"/2023/01/25/Research-FANS/"},{"title":"Continual Graph Convolutional Networks for Text Classification","text":"Our first exploration paper in the field of continual learning has been accepted by AAAI 2023! Tiandeng WU*, Qijiong LIU*, Yao HUANG, Yi CAO, Xiao-Ming WU#, and Jiandong DING#*Equal contribution (co-first authors). Author ordering determined by dice rolling.[Code] [Paper] AbstractTo capture global non-consecutive and long-distance semantic information, graph convolutional network (GCN) has been widely used for text classification. While GCN-based methods have achieved great success in offline evaluations, they usually construct fixed document-token graphs and cannot perform inference on new documents. It is still a challenge to apply GCNs in online systems which need to infer continual text data. In this work, we present a Continual GCN model, short as ContGCN, to generalize inferences from observed documents to unobserved documents. Concretely, we propose a novel global-token-local-document paradigm to dynamically update the document-token graph in every batch for any online system during both training and testing phases. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update the proposed ContGCN in any online system in a label-free manner. Extensive offline experiments conducted on five public datasets demonstrate that our proposed ContGCN can significantly improve inference quality. A 3-month A/B test on our internal online system shows ContGCN achieves 8.86% performance gain compared with state-of-the-art methods. Citation12345678910111213@inproceedings{wu2023contgcn, title = &quot;Continual Graph Convolutional Networks for Text Classification&quot;, author = &quot;Wu, Tiandeng and Liu, Qijiong and Cao, Yi and Huang, Yao and Wu, Xiaoming and Ding, Jiandong&quot;, booktitle = &quot;Proceedings of the 37th AAAI Conference on Artificial Intelligence&quot;, month = feb, year = &quot;2023&quot;, address = &quot;Washington, DC, United States&quot;}","link":"/2022/11/19/Research-ContGCN/"},{"title":"SmartDict: Dynamic pointing of values in Python dictionaries","text":"IntroductionChain assignment of dictionary values, which can be used to reduce redundancy in configuration dictionaries. Installation1pip install smartdict UsageAssuming the following configuration dictionary exists: 1234567891011121314{ &quot;dataset&quot;: &quot;spotify&quot;, &quot;load&quot;: { &quot;train_path&quot;: &quot;~/data/spotify/train&quot;, &quot;dev_path&quot;: &quot;~/data/spotify/dev&quot;, &quot;test_path&quot;: &quot;~/data/spotify/test&quot; }, &quot;network&quot;: { &quot;num_hidden_layers&quot;: 3, &quot;num_attention_heads&quot;: 8, &quot;hidden_size&quot;: 64 }, &quot;store&quot;: &quot;checkpoints/spotify/3L8H/&quot;} It can be observed that many paths such as train_path are related to the dataset name dataset, and the store storage path is related to the dataset name, network structure, and so on. Additionally, if the dataset or network structure is changed, the configuration dictionary needs to be modified complexly. One solution is to handle the redundant information in Python code. For example, the value of train_path is directly assigned to train, in the code as follows: 1data['load']['train_path'] = os.path.join('~', 'data', data['dataset'], data['load']['train_path']) However, this method is not flexible enough. As the number of configuration properties increases, the amount of code required also increases linearly, making the preprocessing of configuration data slightly cumbersome. Normal String Referencing ${}We propose to construct the dictionary values as dynamic data, for example: 123456789101112131415{ &quot;dataset&quot;: &quot;spotify&quot;, &quot;load&quot;: { &quot;base_path&quot;: &quot;~/data/${dataset}&quot;, &quot;train_path&quot;: &quot;${load.base_path}/train&quot;, &quot;dev_path&quot;: &quot;${load.base_path}/dev&quot;, &quot;test_path&quot;: &quot;${load.base_path}/test&quot; }, &quot;network&quot;: { &quot;num_hidden_layers&quot;: 3, &quot;num_attention_heads&quot;: 8, &quot;hidden_size&quot;: 64 }, &quot;store&quot;: &quot;checkpoints/${dataset}/${network.num_hidden_layers}L${network.num_attention_heads}H/&quot;} The value of train_path is dynamically constructed by referencing the value of base_path and train, and the value of store is dynamically constructed by referencing the value of dataset, network.num_hidden_layers, and network.num_attention_heads. The above configuration dictionary can be processed as follows: 123456789101112# solution 1import smartdictdata = smartdict.parse(data)# solution 2from smartdict import DictCompilercompiler = DictCompiler(data)data = compiler.parse()print(data['load']['base_path']) # =&gt; ~/data/spotifyprint(data['load']['dev_path']) # =&gt; ~/data/spotify/devprint(data['store']) # =&gt; checkpoints/spotify/3L8H/ Highly recommended to use smartdict along with Oba: 123456from oba import Objdata = Obj(data)print(data.load.base_path) # =&gt; ~/data/spotifyprint(data.load.dev_path) # =&gt; ~/data/spotify/devprint(data.store) # =&gt; checkpoints/spotify/3L8H/ Full Match Referencing ${}$In the Normal String Referencing ${} solution, the value of the configuration dictionary is a string. The reference is performed through a chain path (separated by .) within the ${} identifier. The Full Match Reference only allows the property value to be completely covered by the identifier ${}$. For example: 123456789101112131415161718import obaimport smartdictdata = dict( a='${b.v.1}+1', # Normal String Referencing b='${c}$', # Full Match Referencing c=dict( l=23, v=('are', 'you', 'ok'), ))data = smartdict.parse(data)print(data['b']) # =&gt; {'l': 23, 'v': ('are', 'you', 'ok')}data = oba.Obj(data)print(data.a) # =&gt; you+1print(data.b.l) # =&gt; 23 In which b is identical to c through the Full Match Reference. Summon MagicSometimes, we may wish to generate the path through timestamps or random numbers. We can first construct the following two classes: TimestampMagic 12345678910111213141516import datetimeclass TimestampMagic(dict): def __init__(self): dict.__init__(self, {}) def __contains__(self, item): return True def __getitem__(self, item): now = datetime.datetime.now() if item == 'str': return now.strftime('%y%m%d-%H%M%S') else: return hex(int(now.timestamp()))[2:] RandomMagic 123456789101112131415import randomimport stringclass RandomMagic(dict): chars = string.ascii_letters + string.digits def __init__(self): dict.__init__(self, {}) def __contains__(self, item): return True def __getitem__(self, item): return ''.join([random.choice(self.chars) for _ in range(int(item))]) Then, we can use the following configuration dictionary: 12345678910111213141516import smartdictdata = dict( filename='${utils.time.str}/${utils.rand.4}.log', # Summon Magic, supported by smartdict&gt;=0.0.4)data.update(dict( utils=dict( rand=Rand(), time=Timing(), )))data = smartdict.parse(data)print(data['filename']) # =&gt; 20221110-123504/to1E.log The principle behind this is to override the class’s [] operator to make it behave the same as a dictionary or list. LicenseMIT Links GitHub PyPI Documentation Chinese version","link":"/2022/11/09/Develop-SmartDict/"},{"title":"Oba: Converting a Python iterable object to an attribute class","text":"IntroductionConverting iterable objects (such as dictionaries, tuples, lists, sets, and subclasses) to access values using class attributes instead of square brackets []. Supports recursive operations and supports both getting and setting values. Installation1pip install oba Usage12345678910111213141516171819from oba import Oba# Convert a dictionary to an attribute classd = dict(a=[1, 2, 3], b=[4, dict(x=1)], c=dict(l='hello'))o = Obj(d)# Get valuesprint(o.a[2]) # =&gt; 3print(o.c.l) # =&gt; hello# Set valueso.b[1].x = 4print(Obj.raw(o.b[1])) # =&gt; {'x': 4}points = [dict(x=1, y=2), dict(x=-1, y=0), dict(x=0, y=1)]o = Obj(points)o[0].x += 1print(Obj.raw(o[0])) # =&gt; {'x': 2, 'y': 2} Comparisonnamedtuple (built-in module)12345678from collections import namedtupleo = namedtuple('Struct', d.keys())(*d.values())print(o) # =&gt; Struct(a=[1, 2, 3], b=[4, {'x': 1}], c={'l': 'hello'})print(o.a) # =&gt; [1, 2, 3]o.x = 2 # =&gt; AttributeError bunch (package)1234567891011from bunch import Buncho = Bunch(d)print(o.a) # =&gt; [1, 2, 3]print(o.b['x']) # =&gt; 1print(o.b.x) # =&gt; KeyErroro.x = 2 # OK, editableo = Bunch(points) # =&gt; AttributeError json (built-in module)1234567891011121314151617import jsonclass Obj(object): def __init__(self, d): self.__dict__.update(d)o = json.loads(json.dumps(d), object_hook=Obj)print(o.a[2]) # =&gt; 3print(o.c.l) # =&gt; helloo.x = 2 # OK, editableo = Obj(points)o[0].x += 1print(o[0].x) # =&gt; 2 mock (package)1234567891011from mock import Mocko = Mock(**d)print(o.a) # =&gt; [1, 2, 3]print(o.b['x']) # =&gt; 1print(o.b.x) # =&gt; KeyErroro.x = 2 # OKo = Mock(*points) # =&gt; TypeError Summary namedtuple bunch (2011) json mock (2020) oba (2022) built-in ✓ ✗ 11K ✓ ✗ 28K ✗ 2K recursive ✗ ✗ ✓ ✗ ✓ revert to raw ✗ ✓ (with extra operations) ✗ ✗ ✓ editable ✗ ✓ ✓ ✓ ✓ iterable ✓ (no keys) ✓ ✗ ✗ ✓ support dict ✓ ✓ ✓ ✓ ✓ support list ✓ ✗ ✓ ✗ ✓ support tuple ✗ ✗ ✓ ✗ ✓ tolerable ✗ ✗ ✗ ✗ ✓ FeaturesAdditionally, Oba also has a unique tolerance for unknown attributes. In cases where some attributes do not exist, for example: 12d = dict(a=1)print(d['b']) # KeyError Other libraries will immediately raise an error. However, in some scenarios (such as reading configuration files), the absence of sub-attributes is a common problem, and we hope to be able to tolerate and monitor the existence of such errors. 123456789from oba import Objd = dict(a=1)o = Obj(d)print('x' in o) # =&gt; Falseif not o.x.y.z: # OK print('not exist') # =&gt; not existprint(o.x.y.z) # =&gt; ValueError: NoneObj (x.y.z) # locating the non-existent attribute chain Its internal implementation is that when an attribute does not exist, the object automatically switches to the NoneObj class and records the attribute chain. LicenseMIT Links GitHub PyPI Documentation Chinese version","link":"/2022/11/07/Develop-Oba/"},{"title":"PREC: Boosting Deep CTR Prediction with a Plug-and-Play Pre-trainer for News Recommendation","text":"The first paper I published as the first author, which is of milestone significance, has been accepted by COLING 2022! Qijiong LIU, Jieming ZHU, Quanyu DAI, Xiao-Ming WU#[Code] [Paper] AbstractUnderstanding news content is critical to improving the quality of news recommendation. To achieve this goal, recent studies have attempted to apply pre-trained language models (PLMs) such as BERT for semantic-enhanced news recommendation. Despite their great success in offline evaluation, it is still a challenge to apply such large PLMs in real-time ranking model due to the stringent requirement in inference and updating time. To bridge this gap, we propose a plug-and-play pre-trainer, namely PREC, to learn both user and news encoders through multi-task pre-training. Instead of directly leveraging sophisticated PLMs for end-to-end inference, we focus on how to use the derived user and item representations to boost the performance of conventional lightweight models for click-through-rate prediction. This enables efficient online inference as well as compatibility to conventional models, which would significantly ease the practical deployment. We validate the effectiveness of PREC through both offline evaluation on public datasets and online A/B testing in an industrial application. Citation1234567891011121314@inproceedings{liu2022prec, title = &quot;Boosting Deep {CTR} Prediction with a Plug-and-Play Pre-trainer for News Recommendation&quot;, author = &quot;Liu, Qijiong and Zhu, Jieming and Dai, Quanyu and Wu, Xiaoming&quot;, booktitle = &quot;Proceedings of the 29th International Conference on Computational Linguistics&quot;, month = oct, year = &quot;2022&quot;, address = &quot;Gyeongju, Republic of Korea&quot;, publisher = &quot;International Committee on Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2022.coling-1.249&quot;, pages = &quot;2823--2833&quot;}","link":"/2022/08/17/Research-PREC/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"package","slug":"package","link":"/tags/package/"},{"name":"research","slug":"research","link":"/tags/research/"},{"name":"life","slug":"life","link":"/tags/life/"},{"name":"recommender system","slug":"recommender-system","link":"/tags/recommender-system/"},{"name":"green AI","slug":"green-AI","link":"/tags/green-AI/"},{"name":"large language model","slug":"large-language-model","link":"/tags/large-language-model/"},{"name":"text classification","slug":"text-classification","link":"/tags/text-classification/"},{"name":"natural language processing","slug":"natural-language-processing","link":"/tags/natural-language-processing/"},{"name":"non-autoregressive generation","slug":"non-autoregressive-generation","link":"/tags/non-autoregressive-generation/"},{"name":"list completion","slug":"list-completion","link":"/tags/list-completion/"},{"name":"vector quantization","slug":"vector-quantization","link":"/tags/vector-quantization/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"semantic tokenization","slug":"semantic-tokenization","link":"/tags/semantic-tokenization/"},{"name":"click-through rate prediction","slug":"click-through-rate-prediction","link":"/tags/click-through-rate-prediction/"}],"categories":[{"name":"Development","slug":"Development","link":"/categories/Development/"},{"name":"Research","slug":"Research","link":"/categories/Research/"}],"pages":[{"title":"Resume","text":"刘奇煚 A brief resume is available in PDF format (Mar. 2024 version). Contact Email: liu@qijiong.work Github: Jyonn Homepage: https://liu.qijiong.work Education2023-2024 (expected)Visiting Scholar, Computing; National University of Singapore (Singapore)2021-2024 (expected)PhD, Computing; The Hong Kong Polytechnic University (Hong Kong SAR)2018-2021MSc, Computer Science; Zhejiang University (China)2014-2018BSc, Software Engineering; Zhejiang University (China)Working ExperienceApr. 2022 - Aug. 2022Algorithm Intern; Huawei Business Group (Nanjing)Sept. 2020 - Jan. 2021Algorithm Intern; Huawei Noah’s Ark Lab (Shenzhen)Aug. 2017 - Jul. 2018Algorithm Intern; Cisco Zeus Group (San Jose)Publications and Preprints span a { color: #4a4a4a; } span i { margin-right: 5px; font-size: 12px; } span i.fa-code { color: burlywood; } span i.fa-paperclip { color: cadetblue; } span i.fa-bookmark { color: mediumpurple; } Large Language Models (UR) Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based RecommendationJiahao WU*, Qijiong LIU*, Hengchang HU, Wenqi FAN, Shengcai LIU, Qing LI#, Xiao-Ming WU#, and Ke TANG#*Equal contribution (co-first authors)Code Paper Page (WSDM’24) ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language ModelsQijiong LIU, Nuo CHEN, Tetsuya SAKAI, and Xiao-Ming WU#Code Paper Page (UR) Making Multimodal Generation Easier: When Diffusion Models Meet LLMsXiangyu ZHAO, Bo LIU*, Qijiong LIU*, Guangyuan SHI*, and Xiao-Ming WU#*Equal contribution (co-second authors)Code Paper Page Recommender System (WWW’24) Semantic Tokenization for Deep CTR PredictionQijiong LIU, Hengchang HU, Jiahao WU, Jieming ZHU, Min-Yen KAN#, Xiao-Ming WU#Code Paper Page (WWW’24) Benchmarking News Recommendation in the Era of Green AIQijiong LIU, Jieming ZHU, Quanyu DAI, Xiao-Ming WU#Code Paper Page (WWW’24) Learning Category Trees for ID-Based Recommendation: Exploring the Power of Differentiable Vector QuantizationQijiong LIU, Lu FAN*, Jiaren XIAO*, Jieming ZHU, and Xiao-Ming WU#*Equal contribution (co-second authors).Code Paper Page (ECIR’24) Lightweight Modality Adaptation to Sequential Recommendation via Correlation SupervisionHengchang HU, Qijiong LIU, Chuang LI, Min-Yen KAN#Code Paper Page (WWW’23) FANS: Fast Non-Autoregressive Sequence Generation for Item List ContinuationQijiong LIU, Jieming ZHU, Jiahao WU, Tiandeng WU, Zhenhua DONG, and Xiao-Ming WU#Code Paper Page (COLING’22) Boosting Deep CTR Prediction with a Plug-and-Play Pre-trainer for News RecommendationQijiong LIU, Jieming ZHU, Quanyu DAI, Xiao-Ming WU#Code Paper Page Natural Language Processing (AAAI’23) Continual Graph Convolutional Network for Text ClassificationTiandeng WU*, Qijiong LIU*, Yao HUANG, Yi CAO, Xiao-Ming WU#, and Jiandong DING#*Equal contribution (co-first authors). Author ordering determined by dice rolling.Code Paper Page (IJCAI’19) Weak Supervision Enhanced Generative Network for Question GenerationYutong WANG, Jiyuan ZHENG, Qijiong LIU, Zhou ZHAO#, Jun XIAO, Yueting ZHUANGPaper Page Selected Award and Honor 2024. ACM MultiMedia 2024 Invited Reviewer 2024. ACM Transactions on Recommender Systems (TORS) Invited Reviewer 2024. ACM Transactions on Information Systems (TOIS) Invited Reviewer 2023. ACM TheWebConf 2024 Invited Reviewer 2023. ACM SIGIR Member 2023. PolyU Research Student Attachment Program (RSAP) 2023. ACM Member 2023. AAAI Student Scholarship 2021. PolyU Research Postgraduate Scholarship 2021. Outstanding Graduate of Zhejiang University 2018. Outstanding Graduate of Zhejiang University 2018. Outstanding Engineer Scholarship of Zhejiang University 2017. Cisco International Internship Program (CIIP) 2016. Student of He Zhijun Class, Zhejiang University Teaching Experience 2023. Teaching Assistant, The Hong Kong Polytechnic University Course: COMP4121: E-Commerce Technology and Application Instructor: Prof. Chun Bun Henry CHAN 2022. Teaching Assistant, The Hong Kong Polytechnic University Course: COMP5523: Computer Vision and Image Processing Instructor: Prof. Xiao-Ming WU 2022. Teaching Assistant, The Hong Kong Polytechnic University Course: COMP5434: Big Data Computing Instructor: Prof. Jieming SHI 2021. Teaching Assistant, The Hong Kong Polytechnic University Course: COMP2011: Data Structures and Algorithms Instructor: Prof. Yixin CAO 2017. Teaching Assistant, Zhejiang University Course: Secure Programming Instructor: Prof. Tianlei HU Selected Side ProjectsMasterWhole | 2020 WeChat Official Account as a toolbox terminal, integrated with Toolbox project and theVideoOfChina project. Framework: Django Fancy tools: Exchange Rate Monitor. Monitor the exchange rate changes (based on data from BANK OF CHINA) and send the notification. Video Downloader. Download the video from popular websites, such as Xin Pianchang, Douyin. Open Source: Code QiqiX (奇奇十号 Qíqí Shíhào in Chinese) | 2020 Article comment mini program for WeChat Official Account, imitating the native WeChat interface. Framework: Wechat Mini Program (WXML, WXSS, JavaScript) Open Source: Code, Documentation (Chinese) RusticCasket (浑天匣 Húntiān Xiá in Chinese) | 2017 Personal webdisk. The bachelor graduation project version uses ISTIO as the microservice architecture design. Framework: Django, Angular, ISTIO Unique Features: Resource Sharing. Users can share resources (files or folders) by generating a link. Resource Description. Users can add markdown-style descriptions to resources. Resource Cover. Users can add covers to resources based on a resource inheritance system. Open Source: Backend, Frontend, and Website (Chinese) More Projects... Open Source PackagesKubeflow (as a contributor) | 2018 Kubeflow is a machine learning toolkit for Kubernetes. It provides a set of tools to help data scientists and developers run machine learning workflows on Kubernetes.Pull Requests: tf-serving support model on NFS, website UniTok | 2021 A unified tokenizer tool for deep learning dataset tokenization. It supports tokenization of textual content, entity content, and customized format such as datetime. Open Source: Code and Documentation SmartDjango | 2019 A high-level packed development framework based on Django, supported by smartify and Oba projects. It is currently used in all my django-based projects. Features: Field Validation. Support for automatic field validation, such as maximum and minimum length in models.CharField and other custom rules. Powerful Request Validation. Support for complex request parameter validation and processing. Smart Model. Support for model-to-dict conversion and list pagination. Default Json Response. Adding one line in settings.py can automatically convert the response to json format. Open Source: Code and Documentation lEmoji | 2020 A versioned emoji character detection tool based on Unicode Emoji Standard and can be manually updated. For now (January 2023), the official package supports emoji detection from v1.0 to v15.0. Usage:1234from lEmoji import EMOJI_LIST_1_0, EMOJI_LIST # EMOJI_LIST is the latest version print('👨‍👩‍👧‍👦' in EMOJI_LIST_1_0) # Falseprint('👨‍👩‍👧‍👦' in EMOJI_LIST) # True Open Source: Code and Documentation smartdict | 2022 A smart dictionary tool that supports the reference of values in the dictionary by key, index, and slice. Usage:1234567import smartdictdata = dict(a=['hello', 'world'], b=&quot;${a}$&quot;, c=&quot;${b.0} python&quot;)data = smartdict.parse(data)print(data['b']) # ['hello', 'world']print(data['c']) # hello python Open Source: Code and Documentation AcknowledgementsAcademic Advisers Ms. Xiao-Ming WU (吴晓明) Mr. Jieming ZHU (朱杰明) Mr. Zhou ZHAO (赵洲) Family Mr. Ziyang LIU and Ms. Huiqin XU Ms. Yanping CHEN Mr. Jiyi CHEN and Ms. Dongmei TAO Mr. Xinqi XU, Mr. Xiangshui LIU, Ms. Jixian SHAO, and Ms. Zhuqiu SHAO Academic Tools PyTorch HuggingFace with transformers Developing Tools JetBrains with PyCharm and WebStorm GitHub with GitHub Student Developer Pack Python with PyPI Hexo","link":"/resume/index.html"},{"title":"projects","text":"MasterWhole | 2020WeChat Official Account as a toolbox terminal, integrated with Toolbox project and theVideoOfChina project. Framework: Django Fancy tools: Exchange Rate Monitor. Monitor the exchange rate changes (based on data from BANK OF CHINA) and send the notification. Video Downloader. Download the video from popular websites, such as Xin Pianchang, Douyin. Open Source: Code QiqiX (奇奇十号 Qíqí Shíhào in Chinese) | 2020Article comment mini program for WeChat Official Account, imitating the native WeChat interface. Framework: Wechat Mini Program (WXML, WXSS, JavaScript) Open Source: Code, Instruction (Chinese) RusticCasket (浑天匣 Húntiān Xiá in Chinese) | 2017Personal webdisk. The bachelor graduation project version uses ISTIO as the microservice architecture design. Framework: Django, Angular, ISTIO Unique Features: Resource Sharing. Users can share resources (files or folders) by generating a link. Resource Description. Users can add markdown-style descriptions to resources. Resource Cover. Users can add covers to resources based on a resource inheritance system. Open Source: Backend and Frontend Website: RusticCasket (Chinese) CosmosBook (齐天簿 Qítian Bù in Chinese) | 2017SSO(Single-Sign-On) central authorization platform based on OAuth2.0. Framework: Django, Angular Unique Features: Central Authorization. Users can use their account to log in to other applications. Application Management. Developers can manage their own applications and set the permissions of the application. Application Center. Variety of applications such as RusticCasket, Shelter, WorldOutlook can be accessed through the application center. Open Source: Backend and Frontend Website: CosmosBook (Chinese) Shelter (投明 Tóumíng in Chinese) | 2019Online replica of iOS Notes app. Framework: Django Open Source: Code Website: Shelter (Chinese) WorldOutlook (世界观 Shìjiè Guān in Chinese) | 2018Multi-user Shad0wS0cks server management platform. Before October 2021, the server built a channel from China to the outside world, and after October 2021, the channel is built from the outside world to China. Framework: Django Open Source: Backend and Frontend Website: WorldOutlook (Chinese)","link":"/projects/index.html"},{"title":"","text":"div.avatar { width:200px; height:200px; background: url('/images/avatar.jpg') 50% 50% no-repeat; background-size: cover; border-radius: 100px; margin: 0 auto 20px auto; border: 3px solid #eee; transition: 0.5s; cursor: pointer; } div.avatar:hover { border: 5px solid #2bbc8a; }","link":"/styles/avatar.css"},{"title":"","text":"img.middle { display: block; margin: 0 auto; width:200px; }","link":"/styles/resume.css"}]}